{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3543139-f322-4ed5-80ba-87c1a5a50fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /home/altheron/.local/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: pandas in /home/altheron/.local/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/altheron/.local/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/altheron/.local/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/altheron/.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy pandas\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ddccd38-d9f2-4425-b7e7-4b5ba154e858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded and saved data from https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\n",
      "     0     1     2    3     4     5     6     7     8     9   ...    48  \\\n",
      "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.00   \n",
      "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.00   \n",
      "2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.01   \n",
      "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
      "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
      "\n",
      "      49   50     51     52     53     54   55    56  57  \n",
      "0  0.000  0.0  0.778  0.000  0.000  3.756   61   278   1  \n",
      "1  0.132  0.0  0.372  0.180  0.048  5.114  101  1028   1  \n",
      "2  0.143  0.0  0.276  0.184  0.010  9.821  485  2259   1  \n",
      "3  0.137  0.0  0.137  0.000  0.000  3.537   40   191   1  \n",
      "4  0.135  0.0  0.135  0.000  0.000  3.537   40   191   1  \n",
      "\n",
      "[5 rows x 58 columns]\n",
      "                0            1            2            3            4   \\\n",
      "count  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000   \n",
      "mean      0.104553     0.213015     0.280656     0.065425     0.312223   \n",
      "std       0.305358     1.290575     0.504143     1.395151     0.672513   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "75%       0.000000     0.000000     0.420000     0.000000     0.380000   \n",
      "max       4.540000    14.280000     5.100000    42.810000    10.000000   \n",
      "\n",
      "                5            6            7            8            9   ...  \\\n",
      "count  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000  ...   \n",
      "mean      0.095901     0.114208     0.105295     0.090067     0.239413  ...   \n",
      "std       0.273824     0.391441     0.401071     0.278616     0.644755  ...   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "75%       0.000000     0.000000     0.000000     0.000000     0.160000  ...   \n",
      "max       5.880000     7.270000    11.110000     5.260000    18.180000  ...   \n",
      "\n",
      "                48           49           50           51           52  \\\n",
      "count  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000   \n",
      "mean      0.038575     0.139030     0.016976     0.269071     0.075811   \n",
      "std       0.243471     0.270355     0.109394     0.815672     0.245882   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%       0.000000     0.065000     0.000000     0.000000     0.000000   \n",
      "75%       0.000000     0.188000     0.000000     0.315000     0.052000   \n",
      "max       4.385000     9.752000     4.081000    32.478000     6.003000   \n",
      "\n",
      "                53           54           55            56           57  \n",
      "count  4601.000000  4601.000000  4601.000000   4601.000000  4601.000000  \n",
      "mean      0.044238     5.191515    52.172789    283.289285     0.394045  \n",
      "std       0.429342    31.729449   194.891310    606.347851     0.488698  \n",
      "min       0.000000     1.000000     1.000000      1.000000     0.000000  \n",
      "25%       0.000000     1.588000     6.000000     35.000000     0.000000  \n",
      "50%       0.000000     2.276000    15.000000     95.000000     0.000000  \n",
      "75%       0.000000     3.706000    43.000000    266.000000     1.000000  \n",
      "max      19.829000  1102.500000  9989.000000  15841.000000     1.000000  \n",
      "\n",
      "[8 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = None\n",
    "file_name = \"spambase.data\"\n",
    "path = \"./datasets/spambase/\" + file_name\n",
    "\n",
    "# Check if directory exists, if not create it\n",
    "os.makedirs(\"./datasets/spambase\", exist_ok=True)\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(path, header=None)\n",
    "    print(f\"Loaded data from {path}\")\n",
    "except FileNotFoundError:\n",
    "    try:\n",
    "        url = (\n",
    "            \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/\"\n",
    "            + file_name\n",
    "        )\n",
    "        df = pd.read_csv(url, header=None)\n",
    "        df.to_csv(path, index=False, header=False)\n",
    "        print(f\"Downloaded and saved data from {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download the file: {e}\")\n",
    "        raise\n",
    "\n",
    "# Check if the dataframe is empty\n",
    "if df.empty:\n",
    "    raise Exception(\"Dataframe is empty\")\n",
    "\n",
    "# Print head and describe\n",
    "print(df.head())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3165b455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there any NA?  False\n"
     ]
    }
   ],
   "source": [
    "# Data exploration\n",
    "is_na = df.isna().any().any()\n",
    "print('Is there any NA? ', is_na)\n",
    "# Il n'y a pas de valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a90e10b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and labels\n",
    "x = df.drop(df.columns[-1], axis=1).values\n",
    "y = df[df.columns[-1]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c0dd553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Train model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e593a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data to remove (in)significant features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af94d03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Predictions on test data\n",
    "y_pred = model.predict(x_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccb14526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Prediction on custom data\n",
    "from api import extract_2d\n",
    "features = extract_2d(\"Tu as gagné 1 million , envoie ton RIB pour recevoir ton gain!!!\")\n",
    "y_pred = model.predict(features)\n",
    "print(y_pred)\n",
    "\n",
    "test_features = extract_2d(\"You have won 1 MILLION $, please send you ADDRESS !!!\")\n",
    "y_pred = model.predict(test_features)\n",
    "print(y_pred)\n",
    "\n",
    "test_features = extract_2d(\n",
    "    \"You won a trip to LAS VEGAS, please send your rib to receive your gain!!!\"\n",
    ")\n",
    "y_pred = model.predict(test_features)\n",
    "print(y_pred)\n",
    "\n",
    "test_features = extract_2d(\n",
    "    \"Has ganado 1 MILLÓN de dinero, por favor envíate la DIRECCIÓN !!!\"\n",
    ")\n",
    "y_pred = model.predict(test_features)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d4fe786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "# import joblib\n",
    "# joblib.dump(model, 'model.pkl')\n",
    "# joblib.dump(scaler, 'scaler.pkl')\n",
    "# print('Model saved as model.pkl')\n",
    "# print('Scaler saved as scaler.pkl')\n",
    "\n",
    "# Load model\n",
    "# model = joblib.load(\"model.pkl\")\n",
    "# scaler = joblib.load(\"scaler.pkl\")\n",
    "# print(\"Model loaded from model.pkl\")\n",
    "# print(\"Scaler loaded from scaler.pkl\")\n",
    "\n",
    "# Predict if the model is still working\n",
    "# y_pred = model.predict(x_test)\n",
    "# print(\"Accuracy: \", model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17aa0c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2024-12-01 15:02:51--  https://spamassassin.apache.org/old/publiccorpus/20021010_spam.tar.bz2\n",
      "Resolving spamassassin.apache.org (spamassassin.apache.org)... 151.101.2.132, 2a04:4e42::644\n",
      "Connecting to spamassassin.apache.org (spamassassin.apache.org)|151.101.2.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1192582 (1.1M) [application/x-bzip2]\n",
      "Saving to: ‘./datasets/spam/20021010_spam.tar.bz2’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  4% 1.82M 1s\n",
      "    50K .......... .......... .......... .......... ..........  8% 2.62M 0s\n",
      "   100K .......... .......... .......... .......... .......... 12% 8.03M 0s\n",
      "   150K .......... .......... .......... .......... .......... 17% 6.00M 0s\n",
      "   200K .......... .......... .......... .......... .......... 21% 3.93M 0s\n",
      "   250K .......... .......... .......... .......... .......... 25% 3.85M 0s\n",
      "   300K .......... .......... .......... .......... .......... 30% 7.44M 0s\n",
      "   350K .......... .......... .......... .......... .......... 34% 14.4M 0s\n",
      "   400K .......... .......... .......... .......... .......... 38% 4.67M 0s\n",
      "   450K .......... .......... .......... .......... .......... 42% 24.6M 0s\n",
      "   500K .......... .......... .......... .......... .......... 47% 11.3M 0s\n",
      "   550K .......... .......... .......... .......... .......... 51% 11.6M 0s\n",
      "   600K .......... .......... .......... .......... .......... 55% 19.1M 0s\n",
      "   650K .......... .......... .......... .......... .......... 60% 15.7M 0s\n",
      "   700K .......... .......... .......... .......... .......... 64% 14.6M 0s\n",
      "   750K .......... .......... .......... .......... .......... 68% 12.8M 0s\n",
      "   800K .......... .......... .......... .......... .......... 72% 27.1M 0s\n",
      "   850K .......... .......... .......... .......... .......... 77% 29.2M 0s\n",
      "   900K .......... .......... .......... .......... .......... 81% 25.1M 0s\n",
      "   950K .......... .......... .......... .......... .......... 85% 20.3M 0s\n",
      "  1000K .......... .......... .......... .......... .......... 90% 12.0M 0s\n",
      "  1050K .......... .......... .......... .......... .......... 94% 21.8M 0s\n",
      "  1100K .......... .......... .......... .......... .......... 98% 25.3M 0s\n",
      "  1150K .......... ....                                       100% 21.6M=0.1s\n",
      "\n",
      "2024-12-01 15:02:51 (7.83 MB/s) - ‘./datasets/spam/20021010_spam.tar.bz2’ saved [1192582/1192582]\n",
      "\n",
      "--2024-12-01 15:02:57--  https://spamassassin.apache.org/old/publiccorpus/20030228_spam.tar.bz2\n",
      "Resolving spamassassin.apache.org (spamassassin.apache.org)... 151.101.2.132, 2a04:4e42::644\n",
      "Connecting to spamassassin.apache.org (spamassassin.apache.org)|151.101.2.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1183768 (1.1M) [application/x-bzip2]\n",
      "Saving to: ‘./datasets/spam/20030228_spam.tar.bz2’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  4% 1.09M 1s\n",
      "    50K .......... .......... .......... .......... ..........  8% 4.99M 1s\n",
      "   100K .......... .......... .......... .......... .......... 12% 10.7M 0s\n",
      "   150K .......... .......... .......... .......... .......... 17% 8.23M 0s\n",
      "   200K .......... .......... .......... .......... .......... 21% 7.60M 0s\n",
      "   250K .......... .......... .......... .......... .......... 25% 11.7M 0s\n",
      "   300K .......... .......... .......... .......... .......... 30% 14.9M 0s\n",
      "   350K .......... .......... .......... .......... .......... 34% 14.8M 0s\n",
      "   400K .......... .......... .......... .......... .......... 38% 18.3M 0s\n",
      "   450K .......... .......... .......... .......... .......... 43% 19.4M 0s\n",
      "   500K .......... .......... .......... .......... .......... 47% 24.0M 0s\n",
      "   550K .......... .......... .......... .......... .......... 51% 15.8M 0s\n",
      "   600K .......... .......... .......... .......... .......... 56% 17.3M 0s\n",
      "   650K .......... .......... .......... .......... .......... 60% 27.3M 0s\n",
      "   700K .......... .......... .......... .......... .......... 64% 10.3M 0s\n",
      "   750K .......... .......... .......... .......... .......... 69% 15.8M 0s\n",
      "   800K .......... .......... .......... .......... .......... 73% 10.4M 0s\n",
      "   850K .......... .......... .......... .......... .......... 77% 15.4M 0s\n",
      "   900K .......... .......... .......... .......... .......... 82% 10.8M 0s\n",
      "   950K .......... .......... .......... .......... .......... 86% 12.2M 0s\n",
      "  1000K .......... .......... .......... .......... .......... 90% 14.3M 0s\n",
      "  1050K .......... .......... .......... .......... .......... 95% 15.9M 0s\n",
      "  1100K .......... .......... .......... .......... .......... 99% 15.4M 0s\n",
      "  1150K ......                                                100% 18.5M=0.1s\n",
      "\n",
      "2024-12-01 15:02:57 (8.58 MB/s) - ‘./datasets/spam/20030228_spam.tar.bz2’ saved [1183768/1183768]\n",
      "\n",
      "--2024-12-01 15:03:04--  https://spamassassin.apache.org/old/publiccorpus/20021010_easy_ham.tar.bz2\n",
      "Resolving spamassassin.apache.org (spamassassin.apache.org)... 151.101.2.132, 2a04:4e42::644\n",
      "Connecting to spamassassin.apache.org (spamassassin.apache.org)|151.101.2.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1677144 (1.6M) [application/x-bzip2]\n",
      "Saving to: ‘./datasets/ham/20021010_easy_ham.tar.bz2’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  3% 7.29M 0s\n",
      "    50K .......... .......... .......... .......... ..........  6% 6.78M 0s\n",
      "   100K .......... .......... .......... .......... ..........  9% 4.46M 0s\n",
      "   150K .......... .......... .......... .......... .......... 12% 6.08M 0s\n",
      "   200K .......... .......... .......... .......... .......... 15% 8.56M 0s\n",
      "   250K .......... .......... .......... .......... .......... 18% 10.6M 0s\n",
      "   300K .......... .......... .......... .......... .......... 21% 8.51M 0s\n",
      "   350K .......... .......... .......... .......... .......... 24% 11.7M 0s\n",
      "   400K .......... .......... .......... .......... .......... 27% 19.2M 0s\n",
      "   450K .......... .......... .......... .......... .......... 30% 26.9M 0s\n",
      "   500K .......... .......... .......... .......... .......... 33% 17.6M 0s\n",
      "   550K .......... .......... .......... .......... .......... 36% 13.2M 0s\n",
      "   600K .......... .......... .......... .......... .......... 39% 27.6M 0s\n",
      "   650K .......... .......... .......... .......... .......... 42% 28.1M 0s\n",
      "   700K .......... .......... .......... .......... .......... 45% 29.1M 0s\n",
      "   750K .......... .......... .......... .......... .......... 48% 45.4M 0s\n",
      "   800K .......... .......... .......... .......... .......... 51% 15.0M 0s\n",
      "   850K .......... .......... .......... .......... .......... 54% 20.5M 0s\n",
      "   900K .......... .......... .......... .......... .......... 58% 32.7M 0s\n",
      "   950K .......... .......... .......... .......... .......... 61% 29.2M 0s\n",
      "  1000K .......... .......... .......... .......... .......... 64% 36.4M 0s\n",
      "  1050K .......... .......... .......... .......... .......... 67% 12.9M 0s\n",
      "  1100K .......... .......... .......... .......... .......... 70% 24.2M 0s\n",
      "  1150K .......... .......... .......... .......... .......... 73% 35.5M 0s\n",
      "  1200K .......... .......... .......... .......... .......... 76% 25.1M 0s\n",
      "  1250K .......... .......... .......... .......... .......... 79% 33.2M 0s\n",
      "  1300K .......... .......... .......... .......... .......... 82% 7.30M 0s\n",
      "  1350K .......... .......... .......... .......... .......... 85% 10.4M 0s\n",
      "  1400K .......... .......... .......... .......... .......... 88% 7.16M 0s\n",
      "  1450K .......... .......... .......... .......... .......... 91% 8.67M 0s\n",
      "  1500K .......... .......... .......... .......... .......... 94% 9.51M 0s\n",
      "  1550K .......... .......... .......... .......... .......... 97% 12.5M 0s\n",
      "  1600K .......... .......... .......... .......              100% 17.2M=0.1s\n",
      "\n",
      "2024-12-01 15:03:04 (12.7 MB/s) - ‘./datasets/ham/20021010_easy_ham.tar.bz2’ saved [1677144/1677144]\n",
      "\n",
      "--2024-12-01 15:03:28--  https://spamassassin.apache.org/old/publiccorpus/20021010_hard_ham.tar.bz2\n",
      "Resolving spamassassin.apache.org (spamassassin.apache.org)... 151.101.2.132, 2a04:4e42::644\n",
      "Connecting to spamassassin.apache.org (spamassassin.apache.org)|151.101.2.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1021126 (997K) [application/x-bzip2]\n",
      "Saving to: ‘./datasets/ham/20021010_hard_ham.tar.bz2’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  5% 2.61M 0s\n",
      "    50K .......... .......... .......... .......... .......... 10% 13.0M 0s\n",
      "   100K .......... .......... .......... .......... .......... 15% 4.35M 0s\n",
      "   150K .......... .......... .......... .......... .......... 20% 2.78M 0s\n",
      "   200K .......... .......... .......... .......... .......... 25% 6.11M 0s\n",
      "   250K .......... .......... .......... .......... .......... 30% 6.07M 0s\n",
      "   300K .......... .......... .......... .......... .......... 35% 7.29M 0s\n",
      "   350K .......... .......... .......... .......... .......... 40% 7.08M 0s\n",
      "   400K .......... .......... .......... .......... .......... 45% 14.2M 0s\n",
      "   450K .......... .......... .......... .......... .......... 50% 13.1M 0s\n",
      "   500K .......... .......... .......... .......... .......... 55% 13.1M 0s\n",
      "   550K .......... .......... .......... .......... .......... 60% 13.2M 0s\n",
      "   600K .......... .......... .......... .......... .......... 65% 13.8M 0s\n",
      "   650K .......... .......... .......... .......... .......... 70% 6.75M 0s\n",
      "   700K .......... .......... .......... .......... .......... 75% 10.4M 0s\n",
      "   750K .......... .......... .......... .......... .......... 80% 11.7M 0s\n",
      "   800K .......... .......... .......... .......... .......... 85% 12.2M 0s\n",
      "   850K .......... .......... .......... .......... .......... 90% 18.0M 0s\n",
      "   900K .......... .......... .......... .......... .......... 95% 14.9M 0s\n",
      "   950K .......... .......... .......... .......... .......   100% 17.2M=0.1s\n",
      "\n",
      "2024-12-01 15:03:29 (7.62 MB/s) - ‘./datasets/ham/20021010_hard_ham.tar.bz2’ saved [1021126/1021126]\n",
      "\n",
      "--2024-12-01 15:03:34--  https://spamassassin.apache.org/old/publiccorpus/20030228_easy_ham.tar.bz2\n",
      "Resolving spamassassin.apache.org (spamassassin.apache.org)... 151.101.2.132, 2a04:4e42::644\n",
      "Connecting to spamassassin.apache.org (spamassassin.apache.org)|151.101.2.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1612216 (1.5M) [application/x-bzip2]\n",
      "Saving to: ‘./datasets/ham/20030228_easy_ham.tar.bz2’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  3%  864K 2s\n",
      "    50K .......... .......... .......... .......... ..........  6% 3.05M 1s\n",
      "   100K .......... .......... .......... .......... ..........  9% 10.5M 1s\n",
      "   150K .......... .......... .......... .......... .......... 12% 6.70M 1s\n",
      "   200K .......... .......... .......... .......... .......... 15% 13.1M 0s\n",
      "   250K .......... .......... .......... .......... .......... 19% 7.40M 0s\n",
      "   300K .......... .......... .......... .......... .......... 22% 13.6M 0s\n",
      "   350K .......... .......... .......... .......... .......... 25% 8.37M 0s\n",
      "   400K .......... .......... .......... .......... .......... 28% 12.3M 0s\n",
      "   450K .......... .......... .......... .......... .......... 31% 10.5M 0s\n",
      "   500K .......... .......... .......... .......... .......... 34% 6.85M 0s\n",
      "   550K .......... .......... .......... .......... .......... 38% 9.62M 0s\n",
      "   600K .......... .......... .......... .......... .......... 41% 13.7M 0s\n",
      "   650K .......... .......... .......... .......... .......... 44% 12.6M 0s\n",
      "   700K .......... .......... .......... .......... .......... 47% 14.3M 0s\n",
      "   750K .......... .......... .......... .......... .......... 50% 9.23M 0s\n",
      "   800K .......... .......... .......... .......... .......... 53% 12.6M 0s\n",
      "   850K .......... .......... .......... .......... .......... 57% 13.2M 0s\n",
      "   900K .......... .......... .......... .......... .......... 60% 20.3M 0s\n",
      "   950K .......... .......... .......... .......... .......... 63% 19.3M 0s\n",
      "  1000K .......... .......... .......... .......... .......... 66% 19.4M 0s\n",
      "  1050K .......... .......... .......... .......... .......... 69% 12.0M 0s\n",
      "  1100K .......... .......... .......... .......... .......... 73% 22.4M 0s\n",
      "  1150K .......... .......... .......... .......... .......... 76% 19.4M 0s\n",
      "  1200K .......... .......... .......... .......... .......... 79% 23.4M 0s\n",
      "  1250K .......... .......... .......... .......... .......... 82% 24.2M 0s\n",
      "  1300K .......... .......... .......... .......... .......... 85% 31.7M 0s\n",
      "  1350K .......... .......... .......... .......... .......... 88% 34.3M 0s\n",
      "  1400K .......... .......... .......... .......... .......... 92% 39.9M 0s\n",
      "  1450K .......... .......... .......... .......... .......... 95% 33.1M 0s\n",
      "  1500K .......... .......... .......... .......... .......... 98% 23.9M 0s\n",
      "  1550K .......... .......... ....                            100% 30.2M=0.2s\n",
      "\n",
      "2024-12-01 15:03:35 (8.60 MB/s) - ‘./datasets/ham/20030228_easy_ham.tar.bz2’ saved [1612216/1612216]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import os\n",
    "\n",
    "# Create directories for spam and ham datasets\n",
    "os.makedirs(\"./datasets/spam\", exist_ok=True)\n",
    "os.makedirs(\"./datasets/ham\", exist_ok=True)\n",
    "\n",
    "# URLs for the datasets\n",
    "datasets = {\n",
    "    \"spam\": [\"20021010_spam.tar.bz2\", \"20030228_spam.tar.bz2\"],\n",
    "    \"ham\": [\n",
    "        \"20021010_easy_ham.tar.bz2\",\n",
    "        \"20021010_hard_ham.tar.bz2\",\n",
    "        \"20030228_easy_ham.tar.bz2\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "# Function to download and extract datasets\n",
    "def download_and_extract(file_name, dataset_type):\n",
    "    url = \"https://spamassassin.apache.org/old/publiccorpus/\" + file_name\n",
    "    os.system(f\"wget {url} -P ./datasets/{dataset_type}\")\n",
    "    tar = tarfile.open(f\"./datasets/{dataset_type}/{file_name}\")\n",
    "    tar.extractall(f\"./datasets/{dataset_type}\")\n",
    "    tar.close()\n",
    "\n",
    "# Download and extract spam datasets\n",
    "for file in datasets[\"spam\"]:\n",
    "    try:\n",
    "        # Check if the file is already downloaded\n",
    "        if not os.path.exists(f\"./datasets/spam/{file}\"):\n",
    "            download_and_extract(file, \"spam\")    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {file} not found\")\n",
    "\n",
    "# Download and extract ham datasets\n",
    "for file in datasets[\"ham\"]:\n",
    "    try:\n",
    "        if not os.path.exists(f\"./datasets/ham/{file}\"):\n",
    "            download_and_extract(file, \"ham\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {file} not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3619ef93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of spam emails: 531\n",
      "Number of ham emails: 4637\n",
      "Spam features: (531, 57)\n",
      "Ham features: (4637, 57)\n",
      "Sample of Spam Features:\n",
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 3.85894877e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 6.91949434e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 4.65735196e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 3.99201597e-01\n",
      "  0.00000000e+00 2.66134398e-01 5.52228876e+00 0.00000000e+00\n",
      "  6.65335995e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.21951220e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.21951220e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.21951220e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.21951220e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.56739409e-01 0.00000000e+00 5.13478819e-01\n",
      "  0.00000000e+00 0.00000000e+00 2.00000000e+00 2.00000000e+00\n",
      "  8.40000000e+01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.44927536e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.44927536e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.44927536e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 6.30914826e-01\n",
      "  0.00000000e+00 0.00000000e+00 2.00000000e+00 2.00000000e+00\n",
      "  7.40000000e+01]]\n",
      "Sample of Ham Features:\n",
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  9.00900901e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 9.00900901e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 9.00900901e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  9.00900901e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  8.10810811e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.23713647e-01\n",
      "  0.00000000e+00 0.00000000e+00 1.30303030e+00 3.00000000e+00\n",
      "  4.30000000e+01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 3.96825397e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 7.93650794e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  3.96825397e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 5.72737686e-02 0.00000000e+00 1.14547537e-01\n",
      "  0.00000000e+00 0.00000000e+00 1.39130435e+00 6.00000000e+00\n",
      "  9.60000000e+01]\n",
      " [6.09756098e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  6.09756098e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.82926829e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 6.09756098e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 6.09756098e-01 0.00000000e+00\n",
      "  6.09756098e-01 0.00000000e+00 6.09756098e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  6.09756098e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  7.92682927e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.07692308e+00 2.00000000e+00\n",
      "  4.20000000e+01]]\n",
      "Labels:\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# All the data is spam\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from api import extract_1d, extract_2d, prioritize_features\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def is_html_content(email_body):\n",
    "    \"\"\"\n",
    "    Check if the email body contains a significant amount of HTML content.\n",
    "    This function filters out emails with minimal HTML.\n",
    "    \"\"\"\n",
    "    if (\n",
    "        re.search(r\"<[^>]+>\", email_body) and email_body.count(\"<\") > 20\n",
    "    ):  # Adjust threshold if needed\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def extract_email_body(email):\n",
    "    \"\"\"\n",
    "    Extract the main content of an email by removing headers.\n",
    "    If no clear separation is found, return the entire email content.\n",
    "    \"\"\"\n",
    "    parts = email.split(\"\\n\\n\", 1)\n",
    "    if len(parts) == 2:\n",
    "        _, body = parts\n",
    "    else:\n",
    "        body = email  # Return the entire content if no clear separation is found\n",
    "    body = body.strip()\n",
    "    return body\n",
    "\n",
    "def load_emails(paths):\n",
    "    emails = []\n",
    "    for path in paths:\n",
    "        for file in os.listdir(path):\n",
    "            file_path = os.path.join(path, file)\n",
    "            if os.path.isfile(file_path):\n",
    "                with open(file_path, \"r\", errors=\"ignore\") as f:\n",
    "                    email_content = f.read()\n",
    "                    if not is_html_content(email_content):\n",
    "                        emails.append(extract_email_body(email_content))\n",
    "    return emails\n",
    "\n",
    "\n",
    "# Path to spam and ham datasets\n",
    "spam_path = [\"./datasets/spam/spam\"]\n",
    "ham_paths = [\"./datasets/ham/easy_ham\", \"./datasets/ham/hard_ham\"]\n",
    "# Load spam emails\n",
    "spam_emails = load_emails(spam_path)\n",
    "ham_emails = load_emails(ham_paths)\n",
    "\n",
    "print(f\"Number of spam emails: {len(spam_emails)}\")\n",
    "print(f\"Number of ham emails: {len(ham_emails)}\")\n",
    "\n",
    "spam_features = np.array([extract_1d(email) for email in spam_emails])\n",
    "ham_features = np.array([extract_1d(email) for email in ham_emails])\n",
    "\n",
    "# On priorise les features les plus importantes\n",
    "spam_features = prioritize_features(spam_features)\n",
    "\n",
    "print(f'Spam features: {spam_features.shape}')\n",
    "print(f'Ham features: {ham_features.shape}')\n",
    "\n",
    "# Labels: 1 for spam, 0 for ham\n",
    "spam_labels = np.ones(len(spam_features))\n",
    "ham_labels = np.zeros(len(ham_features))\n",
    "\n",
    "# Combine spam and ham features and labels using np.concatenate\n",
    "all_features = np.concatenate((spam_features, ham_features), axis=0) \n",
    "all_labels = np.concatenate((spam_labels, ham_labels), axis=0)\n",
    "\n",
    "# Display features and labels for verification\n",
    "print(\"Sample of Spam Features:\") \n",
    "print(spam_features[:3]) \n",
    "print(\"Sample of Ham Features:\") \n",
    "print(ham_features[:3]) \n",
    "print(\"Labels:\") \n",
    "print(all_labels[:20])\n",
    "\n",
    "# Split into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    all_features, all_labels, test_size=0.2, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7ae308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "583801a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[917   2]\n",
      " [  0 115]]\n",
      "Accuracy: 99.81%\n",
      "Precision: 98.29%\n",
      "Recall: 100.00%\n",
      "F1 Score: 99.14%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       919\n",
      "           1       0.98      1.00      0.99       115\n",
      "\n",
      "    accuracy                           1.00      1034\n",
      "   macro avg       0.99      1.00      1.00      1034\n",
      "weighted avg       1.00      1.00      1.00      1034\n",
      "\n",
      "'You have won a free trip to Paris! Reply to this email to claim your prize GO CHECK YOUR EMAIL NOW' is classified as SPAM.\n",
      "'Coucou maman' is classified as NOT SPAM.\n",
      "'You have won 1 million dollars! Please send your bank details to claim your prize.' is classified as NOT SPAM.\n",
      "'Your account has been suspended. Please verify your identity to restore access.' is classified as NOT SPAM.\n",
      "'Salut je vais te hacker ramnène moi 500 EUROS dans les 24 heures!!!!!!' is classified as SPAM.\n",
      "'Meeting tomorrow at 10 AM. Please confirm your attendance.' is classified as NOT SPAM.\n",
      "Mean Features for Spam Emails:\n",
      "[1.98825644e-01 1.64285510e-01 7.00173210e-01 1.00801522e+00\n",
      " 2.16537140e+00 2.38738067e-01 3.15466972e-01 5.68000659e-02\n",
      " 8.31614590e-02 1.14270085e+00 1.54572363e-01 4.36928268e-01\n",
      " 1.28420408e-01 3.83235691e-02 3.43621811e-02 2.00878423e-01\n",
      " 6.91128736e-02 4.20169541e-01 2.78664690e+00 4.38404350e-02\n",
      " 1.17808594e+00 1.43335887e-02 7.20756417e-01 1.53724137e-01\n",
      " 4.22071580e-01 1.55703941e-04 0.00000000e+00 3.36845388e-03\n",
      " 1.08647382e-01 0.00000000e+00 0.00000000e+00 1.66079169e-03\n",
      " 3.33977196e-02 5.59316488e-03 4.13758440e-01 8.13720476e-03\n",
      " 3.50885291e-03 3.56245088e-03 1.15662315e-01 4.50780700e-02\n",
      " 7.56785721e-02 1.64250849e-03 3.27532655e-02 3.84933769e-02\n",
      " 5.86473660e+00 1.46319004e-02 4.31692868e-02 0.00000000e+00\n",
      " 3.36823175e-02 1.68495715e-01 4.67663482e-02 4.81264394e-01\n",
      " 2.66440866e-01 1.72089622e-01 3.52199064e+00 1.58041431e+01\n",
      " 2.24424105e+03]\n",
      "Mean Features for Ham Emails:\n",
      "[1.13580792e-01 4.69911993e-02 9.38223796e-01 2.77214710e-02\n",
      " 1.11241756e+00 2.27471408e-01 2.69182704e-02 1.34593807e-02\n",
      " 2.29441952e-02 8.39641955e-01 5.38728563e-02 2.03502934e-01\n",
      " 1.15947274e-01 6.35833556e-02 1.29677690e-02 1.15819329e+00\n",
      " 2.87817025e-02 1.92635066e-01 8.70510680e-01 7.62650895e-03\n",
      " 2.64531798e-01 1.20691435e-02 1.62992274e-01 2.28629877e-02\n",
      " 4.56363643e-02 1.01786737e-04 0.00000000e+00 2.34402602e-02\n",
      " 4.62395549e-02 9.52884683e-04 2.46132116e-03 3.04794742e-02\n",
      " 6.88039691e-02 1.14391522e-02 1.95027515e-01 2.20177092e-02\n",
      " 1.01083196e-02 8.96597122e-03 4.51137321e-01 6.17277898e-02\n",
      " 1.84250289e-01 6.85300054e-03 2.39533011e-02 3.09767593e-02\n",
      " 7.20474397e+00 7.72466010e-02 4.86392576e-02 2.77280598e-02\n",
      " 3.39660101e-02 1.44454937e-01 1.19183278e-01 5.22818012e-02\n",
      " 1.51786643e-02 7.50648906e-02 1.31252515e+00 3.72503774e+00\n",
      " 7.32536122e+01]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "from api import extract_2d\n",
    "\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "# Assuming your labels are 0 for non-spam and 1 for spam\n",
    "all_labels = [0, 1]\n",
    "\n",
    "# Generate the confusion matrix with specified labels\n",
    "cm = confusion_matrix(y_test, y_pred, labels=all_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "# Generate a classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, labels=all_labels))\n",
    "\n",
    "# New sample inputs for prediction\n",
    "emails_to_test = [\n",
    "    \"You have won a free trip to Paris! Reply to this email to claim your prize GO CHECK YOUR EMAIL NOW\",\n",
    "    \"Coucou maman\",\n",
    "    \"You have won 1 million dollars! Please send your bank details to claim your prize.\",\n",
    "    \"Your account has been suspended. Please verify your identity to restore access.\",\n",
    "    \"Salut je vais te hacker ramnène moi 500 EUROS dans les 24 heures!!!!!!\",\n",
    "    \"Meeting tomorrow at 10 AM. Please confirm your attendance.\",\n",
    "    \"Your order has been confirmed. Click the link to track your delivery.\",\n",
    "]\n",
    "\n",
    "# Predict and display results\n",
    "for email in emails_to_test:\n",
    "    features = extract_2d(email)\n",
    "    y_pred = model.predict(features)\n",
    "    if y_pred == 1:\n",
    "        print(f\"'{email}' is classified as SPAM.\")\n",
    "    else:\n",
    "        print(f\"'{email}' is classified as NOT SPAM.\")\n",
    "\n",
    "spam_mean_features = np.mean(spam_features, axis=0)\n",
    "ham_mean_features = np.mean(ham_features, axis=0)\n",
    "\n",
    "print(\"Mean Features for Spam Emails:\")\n",
    "print(spam_mean_features)\n",
    "print(\"Mean Features for Ham Emails:\")\n",
    "print(ham_mean_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
